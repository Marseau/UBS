/**
 * Instagram Lead Scraper - C√≥digo JavaScript para N8N
 * USO: Copie este c√≥digo para um n√≥ "Code" no N8N
 *
 * IMPORTANTE:
 * 1. Voc√™ precisa estar LOGADO no Instagram antes de executar
 * 2. Este c√≥digo usa HTTP Request + Puppeteer MCP
 * 3. Adicione delays aleat√≥rios para evitar detec√ß√£o
 */

// ========== CONFIGURA√á√ÉO ==========
const INSTAGRAM_BASE_URL = 'https://www.instagram.com';
const MIN_FOLLOWERS = 500; // M√≠nimo de seguidores
const MIN_POSTS = 10; // M√≠nimo de posts
const DELAY_MIN = 5000; // 5 segundos
const DELAY_MAX = 15000; // 15 segundos
const MAX_PROFILES_PER_TERM = 5; // M√°ximo de perfis por termo

// ========== DADOS DE ENTRADA ==========
const sessionData = $input.first().json;
const terms = sessionData.terms; // Array de termos de busca
const sessionId = sessionData.session_id;
const segment = sessionData.segment;

console.log(`üöÄ Iniciando scraping: ${terms.length} termos`);
console.log(`üìä Segmento: ${segment}`);

// ========== FUN√á√ïES AUXILIARES ==========

/**
 * Aguarda um tempo aleat√≥rio para simular comportamento humano
 */
async function randomDelay() {
  const delay = DELAY_MIN + Math.random() * (DELAY_MAX - DELAY_MIN);
  console.log(`‚è≥ Aguardando ${(delay / 1000).toFixed(1)}s...`);
  await new Promise(resolve => setTimeout(resolve, delay));
}

/**
 * Extrai dados de um perfil do Instagram
 * ATEN√á√ÉO: Este c√≥digo precisa ser ajustado conforme a estrutura HTML do Instagram
 */
function extractProfileData(html, term) {
  // IMPORTANTE: Seletores CSS podem mudar! Verifique no DevTools do Chrome

  // Exemplo de extra√ß√£o (AJUSTE CONFORME NECESS√ÅRIO):
  const usernameMatch = html.match(/"username":"([^"]+)"/);
  const fullNameMatch = html.match(/"full_name":"([^"]+)"/);
  const bioMatch = html.match(/"biography":"([^"]+)"/);
  const followersMatch = html.match(/"edge_followed_by":\\{"count":([0-9]+)\\}/);
  const followingMatch = html.match(/"edge_follow":\\{"count":([0-9]+)\\}/);
  const postsMatch = html.match(/"edge_owner_to_timeline_media":\\{"count":([0-9]+)\\}/);
  const isBusinessMatch = html.match(/"is_business_account":(true|false)/);
  const isVerifiedMatch = html.match(/"is_verified":(true|false)/);
  const profilePicMatch = html.match(/"profile_pic_url":"([^"]+)"/);
  const emailMatch = html.match(/"public_email":"([^"]+)"/);
  const phoneMatch = html.match(/"public_phone_number":"([^"]+)"/);
  const websiteMatch = html.match(/"external_url":"([^"]+)"/);
  const categoryMatch = html.match(/"category_name":"([^"]+)"/);

  if (!usernameMatch) {
    return null; // Perfil n√£o encontrado
  }

  const followers = followersMatch ? parseInt(followersMatch[1]) : 0;
  const posts = postsMatch ? parseInt(postsMatch[1]) : 0;
  const isBusiness = isBusinessMatch ? isBusinessMatch[1] === 'true' : false;

  // Filtrar por crit√©rios m√≠nimos
  if (followers < MIN_FOLLOWERS || posts < MIN_POSTS) {
    console.log(`‚è≠Ô∏è  Perfil @${usernameMatch[1]} ignorado (${followers} followers, ${posts} posts)`);
    return null;
  }

  return {
    username: usernameMatch[1],
    full_name: fullNameMatch ? fullNameMatch[1] : null,
    bio: bioMatch ? bioMatch[1].replace(/\\n/g, ' ') : null,
    profile_pic_url: profilePicMatch ? profilePicMatch[1] : null,
    is_business_account: isBusiness,
    is_verified: isVerifiedMatch ? isVerifiedMatch[1] === 'true' : false,
    followers_count: followers,
    following_count: followingMatch ? parseInt(followingMatch[1]) : 0,
    posts_count: posts,
    email: emailMatch ? emailMatch[1] : null,
    phone: phoneMatch ? phoneMatch[1] : null,
    website: websiteMatch ? websiteMatch[1] : null,
    business_category: categoryMatch ? categoryMatch[1] : null,
    search_term_used: term
  };
}

/**
 * Busca perfis para um termo espec√≠fico usando HTTP Request para Mac
 */
async function searchProfiles(term) {
  console.log(`\nüîç Buscando: "${term}"`);

  try {
    // Passo 1: Buscar usernames da hashtag via HTTP Request no Mac
    const scrapeTagUrl = 'http://192.168.15.5:3000/api/instagram-scraper/scrape-tag';
    const tagResponse = await $http.post(scrapeTagUrl, {
      search_term: term,
      max_profiles: MAX_PROFILES_PER_TERM
    });

    const usernames = tagResponse.data?.data?.usernames || [];
    console.log(`   üìã Encontrados ${usernames.length} usernames em #${term}`);

    if (usernames.length === 0) {
      return [];
    }

    // Passo 2: Para cada username, buscar dados completos do perfil
    const profiles = [];
    for (const username of usernames) {
      try {
        console.log(`   üë§ Buscando dados: @${username}`);

        const scrapeProfileUrl = 'http://192.168.15.5:3000/api/instagram-scraper/scrape-profile';
        const profileResponse = await $http.post(scrapeProfileUrl, {
          username: username
        });

        const profileData = profileResponse.data?.data;

        if (profileData) {
          // Aplicar filtros de qualifica√ß√£o
          const followers = profileData.followers_count || 0;
          const posts = profileData.posts_count || 0;

          if (followers >= MIN_FOLLOWERS && posts >= MIN_POSTS) {
            profiles.push({
              username: profileData.username,
              full_name: profileData.full_name,
              bio: profileData.bio,
              profile_pic_url: profileData.profile_pic_url,
              is_business_account: profileData.is_business_account,
              is_verified: profileData.is_verified,
              followers_count: followers,
              following_count: profileData.following_count || 0,
              posts_count: posts,
              email: profileData.email,
              phone: profileData.phone,
              website: profileData.website,
              business_category: profileData.business_category,
              search_term_used: term
            });
            console.log(`   ‚úÖ Perfil qualificado: @${username} (${followers} followers, ${posts} posts)`);
          } else {
            console.log(`   ‚è≠Ô∏è Perfil ignorado: @${username} (${followers} followers, ${posts} posts)`);
          }
        }

        // Delay entre perfis
        await randomDelay();

      } catch (profileError) {
        console.error(`   ‚ùå Erro ao buscar @${username}:`, profileError.message);
        continue;
      }
    }

    return profiles;

  } catch (error) {
    console.error(`‚ùå Erro ao buscar "${term}":`, error.message);
    return [];
  }
}

// ========== LOOP PRINCIPAL DE SCRAPING ==========

const allLeads = [];
let termsProcessed = 0;

for (const term of terms) {
  try {
    // Buscar perfis para este termo
    const profiles = await searchProfiles(term);

    if (profiles.length > 0) {
      console.log(`‚úÖ Encontrados ${profiles.length} perfis para "${term}"`);
      allLeads.push(...profiles);
    } else {
      console.log(`‚ö†Ô∏è  Nenhum perfil qualificado para "${term}"`);
    }

    termsProcessed++;

    // Delay entre termos (exceto √∫ltimo)
    if (termsProcessed < terms.length) {
      await randomDelay();
    }

  } catch (error) {
    console.error(`‚ùå Erro processando termo "${term}":`, error.message);

    // Continuar com pr√≥ximo termo
    continue;
  }
}

// ========== RESULTADO ==========

console.log(`\nüéâ Scraping conclu√≠do!`);
console.log(`üìä Termos processados: ${termsProcessed}/${terms.length}`);
console.log(`üë• Leads encontrados: ${allLeads.length}`);
console.log(`üë• Leads √∫nicos (antes de salvar): ${allLeads.length}`);

// Retornar leads para pr√≥ximo n√≥ processar
// NOTA: A atualiza√ß√£o da sess√£o deve ser feita em um n√≥ Postgres separado ao final
return allLeads.map(lead => ({
  json: {
    ...lead,
    session_id: sessionId,
    segment: segment,
    // Adicionar dados para c√°lculo de score
    lead_score: lead.followers_count >= 500 ? 0.85 : 0.65,
    is_qualified: lead.followers_count >= MIN_FOLLOWERS && lead.posts_count >= MIN_POSTS,
    // Timestamps
    captured_at: new Date().toISOString(),
    created_at: new Date().toISOString(),
    updated_at: new Date().toISOString()
  }
}));


// ========== INSTRU√á√ïES DE USO ==========
/**
 *
 * COMO USAR ESTE C√ìDIGO NO N8N:
 *
 * ARQUITETURA: N8N (Servidor) ‚Üí HTTP Request ‚Üí Mac (Express + Puppeteer) ‚Üí Supabase
 *
 * 1. PREPARA√á√ÉO NO MAC:
 *    - Inicie o servidor Express: npm start
 *    - URL: http://192.168.15.5:3000
 *    - Na primeira execu√ß√£o, o browser abrir√° automaticamente
 *    - Voc√™ ter√° 90 SEGUNDOS para fazer login no Instagram
 *    - O browser permanecer√° aberto e logado para pr√≥ximas execu√ß√µes
 *
 * 2. Crie um workflow no N8N com estes n√≥s:
 *    - Manual Trigger
 *    - Supabase: Fetch Unused Terms (busca search_terms onde times_used = 0)
 *    - Supabase: Create Scraping Session (cria registro em instagram_scraping_sessions)
 *    - Code: Prepare Data (extrai array de termos)
 *    - **Code (ESTE ARQUIVO)**: Loop de scraping via HTTP
 *    - Supabase/Postgres: Insert Lead (salva cada lead)
 *    - Postgres: Update Session Complete (atualiza m√©tricas da sess√£o)
 *
 * 3. ENDPOINTS DISPON√çVEIS NO MAC:
 *    - POST /api/instagram-scraper/scrape-tag
 *      Body: { "search_term": "gestor_de_trafego", "max_profiles": 10 }
 *      Retorna: { "success": true, "data": { "usernames": [...] } }
 *
 *    - POST /api/instagram-scraper/scrape-profile
 *      Body: { "username": "exemplo_usuario" }
 *      Retorna: { "success": true, "data": { username, full_name, bio, ... } }
 *
 *    - POST /api/instagram-scraper/close-browser
 *      Fecha o browser (chamar ao final do dia)
 *
 *    - GET /api/instagram-scraper/status
 *      Verifica se servi√ßo est√° ativo
 *
 * 4. FLUXO DE DADOS:
 *    1. N8N busca termos do banco (lead_search_terms)
 *    2. Cria sess√£o de scraping (instagram_scraping_sessions)
 *    3. Para cada termo:
 *       - HTTP Request ‚Üí Mac scrape-tag ‚Üí Retorna usernames
 *       - Para cada username:
 *         - HTTP Request ‚Üí Mac scrape-profile ‚Üí Retorna dados completos
 *         - Filtra por MIN_FOLLOWERS e MIN_POSTS
 *         - Adiciona ao array de leads
 *    4. Retorna todos os leads para pr√≥ximo n√≥ salvar no banco
 *
 * 5. ANTI-DETEC√á√ÉO:
 *    - Use delays aleat√≥rios entre requisi√ß√µes (5-15s)
 *    - Limite a 20-30 termos por sess√£o
 *    - Varie hor√°rios de execu√ß√£o
 *    - Delays autom√°ticos de 2-5s entre cada requisi√ß√£o (j√° implementado no Mac)
 *    - Limite a 20-30 termos por sess√£o
 *    - Browser singleton mant√©m sess√£o logada (evita logins repetidos)
 *
 * 6. TROUBLESHOOTING:
 *    - Erro "socket hang up" / ECONNRESET:
 *      ‚Üí Servidor Mac n√£o est√° rodando ou IP errado
 *      ‚Üí Verifique: curl http://192.168.15.5:3000/api/instagram-scraper/status
 *
 *    - Instagram pedir login:
 *      ‚Üí Sess√£o expirou ou √© primeira execu√ß√£o
 *      ‚Üí Aguarde 90s ap√≥s iniciar servidor para fazer login manual
 *      ‚Üí Browser permanecer√° aberto e logado
 *
 *    - Aparecer CAPTCHA:
 *      ‚Üí Resolva manualmente no browser que est√° aberto
 *      ‚Üí Workflow continuar√° ap√≥s resolver
 *
 *    - Muitos perfis ignorados (n√£o qualificados):
 *      ‚Üí Ajuste MIN_FOLLOWERS e MIN_POSTS no topo do script
 *      ‚Üí Padr√£o: 500 followers e 10 posts
 *
 *    - Poucos usernames encontrados:
 *      ‚Üí Aumente MAX_PROFILES_PER_TERM (padr√£o: 5)
 *      ‚Üí Teste hashtags mais populares
 *
 * 7. MONITORAMENTO:
 *    - Logs do Mac: Mostram cada requisi√ß√£o e delay
 *    - Logs do N8N: Mostram progresso do scraping
 *    - Banco de dados: instagram_scraping_sessions rastreia m√©tricas
 *
 */
