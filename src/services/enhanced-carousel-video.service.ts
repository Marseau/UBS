import axios from 'axios';
import * as fs from 'fs';
import * as path from 'path';
import * as os from 'os';
import { exec } from 'child_process';
import { promisify } from 'util';

const execAsync = promisify(exec);

interface EnhancedVideoOptions {
  backgroundMusicUrl?: string;
  voiceoverScript?: string;
  voiceoverScriptPerSlide?: string[]; // Script sincronizado por slide
  voicePerSlide?: ('bruno' | 'carla')[]; // Voz por slide: 'bruno' ou 'carla'
  finalStaticSlide?: {
    imageUrl: string;      // URL da imagem do slide final est√°tico
    duration: number;      // Dura√ß√£o em segundos (ex: 3)
  };
  musicVolume?: number; // 0.0 to 1.0 (default: 0.3)
  useFadeTransitions?: boolean; // default: true
  fadeTransitionDuration?: number; // seconds (default: 0.5)
}

interface EnhancedVideoResult {
  video_url: string;
  duration_seconds: number;
  total_slides: number;
  content_id: string;
  cost_usd: number;
  voiceover_url?: string;
  music_used: boolean;
  transitions_used: boolean;
}

export class EnhancedCarouselVideoService {
  private readonly ELEVENLABS_API_KEY: string;
  private readonly ELEVENLABS_VOICE_ID_BRUNO: string;
  private readonly ELEVENLABS_VOICE_ID_CARLA: string;
  private readonly ELEVENLABS_COST_PER_1K_CHARS = 0.30;

  constructor() {
    this.ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY || '';
    this.ELEVENLABS_VOICE_ID_BRUNO = process.env.ELEVENLABS_VOICE_ID_Bruno || '';
    this.ELEVENLABS_VOICE_ID_CARLA = process.env.ELEVENLABS_VOICE_ID_Carla || '';
  }

  /**
   * Gera v√≠deo carrossel com transi√ß√µes fade, m√∫sica e locu√ß√£o do Bruno
   */
  async generateEnhancedVideo(
    imageUrls: string[],
    contentId: string,
    duration: number = 60,
    options: EnhancedVideoOptions = {}
  ): Promise<EnhancedVideoResult> {
    console.log('üé¨ ========== INICIANDO GERA√á√ÉO V√çDEO ENHANCED ==========');
    console.log(`üìÑ Content ID: ${contentId}`);
    console.log(`üñºÔ∏è Total de imagens: ${imageUrls.length}`);
    console.log(`‚è±Ô∏è Dura√ß√£o alvo: ${duration}s`);
    console.log(`üéµ M√∫sica: ${options.backgroundMusicUrl ? 'SIM' : 'N√ÉO'}`);
    console.log(`üéôÔ∏è Locu√ß√£o Bruno: ${options.voiceoverScript ? 'SIM' : 'N√ÉO'}`);
    console.log(`‚ú® Transi√ß√µes fade: ${options.useFadeTransitions !== false ? 'SIM' : 'N√ÉO'}`);

    const tempDir = path.join(os.tmpdir(), `enhanced-carousel-${contentId}-${Date.now()}`);
    fs.mkdirSync(tempDir, { recursive: true });

    let voiceoverPath: string | undefined;
    let musicPath: string | undefined;
    let totalCost = imageUrls.length * 0.076; // Placid cost

    try {
      // 1. Download das imagens
      console.log('\nüì• Fazendo download das imagens...');
      const imagePaths: string[] = [];

      for (let i = 0; i < imageUrls.length; i++) {
        const imageUrl = imageUrls[i];
        if (!imageUrl) continue;

        console.log(`   ‚¨áÔ∏è Baixando slide ${i + 1}/${imageUrls.length}...`);
        const imagePath = path.join(tempDir, `slide-${i.toString().padStart(2, '0')}.jpg`);

        const response = await axios.get(imageUrl, { responseType: 'arraybuffer' });
        fs.writeFileSync(imagePath, response.data);
        imagePaths.push(imagePath);
      }

      // 1.1 Download do slide final est√°tico (se fornecido)
      if (options.finalStaticSlide) {
        console.log('\nüéØ Baixando slide final est√°tico (CTA)...');
        const finalImagePath = path.join(tempDir, `slide-${imagePaths.length.toString().padStart(2, '0')}.jpg`);
        const response = await axios.get(options.finalStaticSlide.imageUrl, { responseType: 'arraybuffer' });
        fs.writeFileSync(finalImagePath, response.data);
        imagePaths.push(finalImagePath);
        console.log(`   ‚úÖ Slide final adicionado com ${options.finalStaticSlide.duration}s de dura√ß√£o`);
      }

      // 2. Gerar locu√ß√£o do Bruno (sincronizada ou monol√≠tica)
      let voiceoverDurations: number[] = [];
      let syncedVoiceovers: string[] = [];

      if (options.voiceoverScriptPerSlide && this.ELEVENLABS_API_KEY) {
        // MODO SINCRONIZADO: Gerar √°udio por slide com suporte a m√∫ltiplas vozes
        const { audioPaths, durations, totalDuration } = await this.generateSyncedVoiceovers(
          options.voiceoverScriptPerSlide,
          tempDir,
          options.voicePerSlide // Array opcional de vozes: 'bruno' ou 'carla'
        );
        syncedVoiceovers = audioPaths;
        voiceoverDurations = durations;
        totalCost += options.voiceoverScriptPerSlide.join('').length / 1000 * this.ELEVENLABS_COST_PER_1K_CHARS;

        // Ajustar dura√ß√£o total para coincidir com narra√ß√£o
        duration = Math.max(duration, totalDuration + 2); // +2s de margem
        console.log(`\n‚è±Ô∏è Dura√ß√£o ajustada para ${duration.toFixed(2)}s (baseado na narra√ß√£o)`);
      } else if (options.voiceoverScript && this.ELEVENLABS_API_KEY) {
        // MODO ANTIGO: Gerar √°udio √∫nico
        console.log('\nüéôÔ∏è Gerando locu√ß√£o do Bruno via ElevenLabs...');
        voiceoverPath = await this.generateVoiceover(
          options.voiceoverScript,
          tempDir
        );
        totalCost += (options.voiceoverScript.length / 1000) * this.ELEVENLABS_COST_PER_1K_CHARS;
        console.log(`‚úÖ Locu√ß√£o gerada: ${voiceoverPath}`);
      }

      // 3. Download da m√∫sica de fundo (se fornecida)
      if (options.backgroundMusicUrl) {
        console.log('\nüéµ Fazendo download da m√∫sica de fundo...');
        musicPath = path.join(tempDir, 'background-music.mp3');
        const musicResponse = await axios.get(options.backgroundMusicUrl, {
          responseType: 'arraybuffer'
        });
        fs.writeFileSync(musicPath, musicResponse.data);
        console.log('‚úÖ M√∫sica baixada');
      }

      // 4. Calcular dura√ß√£o por slide (sincronizada ou distribu√≠da)
      let durationsPerSlide: number[];

      if (voiceoverDurations.length > 0) {
        // Usar dura√ß√µes reais dos √°udios + pequena margem
        durationsPerSlide = voiceoverDurations.map(d => d + 0.5);

        // Adicionar dura√ß√£o do slide final est√°tico (sem locu√ß√£o)
        if (options.finalStaticSlide) {
          durationsPerSlide.push(options.finalStaticSlide.duration);
        }

        console.log(`\n‚è±Ô∏è Dura√ß√µes sincronizadas por slide:`, durationsPerSlide.map(d => d.toFixed(2) + 's'));
      } else {
        // Distribuir uniformemente (considerando slide final se existir)
        const totalSlides = options.finalStaticSlide ? imageUrls.length + 1 : imageUrls.length;
        const durationPerSlide = duration / totalSlides;
        durationsPerSlide = Array(totalSlides).fill(durationPerSlide);
        console.log(`\n‚è±Ô∏è Dura√ß√£o por slide: ${durationPerSlide.toFixed(2)}s`);
      }

      // 5. Gerar v√≠deo com ou sem transi√ß√µes fade
      const outputVideoPath = path.join(tempDir, `carousel-${contentId}.mp4`);

      if (options.useFadeTransitions !== false) {
        await this.generateVideoWithFadeTransitionsSynced(
          imagePaths,
          outputVideoPath,
          durationsPerSlide,
          options.fadeTransitionDuration || 0.5,
          syncedVoiceovers // √Åudios sincronizados (se existirem)
        );
      } else {
        await this.generateVideoSimpleSynced(imagePaths, outputVideoPath, durationsPerSlide, syncedVoiceovers);
      }

      // 6. Adicionar m√∫sica de fundo ao v√≠deo sincronizado
      if (musicPath && syncedVoiceovers.length > 0) {
        console.log('\nüéµ Adicionando m√∫sica de fundo ao v√≠deo sincronizado...');
        const finalVideoPath = path.join(tempDir, `final-${contentId}.mp4`);

        // Adicionar m√∫sica como trilha de fundo (mixada com locu√ß√µes j√° embutidas)
        const mixCommand = `ffmpeg -i "${outputVideoPath}" -i "${musicPath}" \
          -filter_complex "[1:a]volume=${options.musicVolume || 0.15},afade=t=in:st=0:d=2,afade=t=out:st=${duration - 2}:d=2[music]; \
            [0:a][music]amix=inputs=2:duration=first:weights=1 ${options.musicVolume || 0.15}[audio]" \
          -map 0:v -map "[audio]" \
          -c:v copy -c:a aac -b:a 192k \
          -shortest \
          -y "${finalVideoPath}"`;

        await execAsync(mixCommand);
        fs.renameSync(finalVideoPath, outputVideoPath);
        console.log('   ‚úÖ M√∫sica de fundo adicionada');

      } else if ((voiceoverPath || musicPath) && syncedVoiceovers.length === 0) {
        // Modo antigo: √°udio √∫nico
        console.log('\nüéµ Adicionando √°udio ao v√≠deo...');
        const finalVideoPath = path.join(tempDir, `final-${contentId}.mp4`);
        await this.addAudioToVideo(
          outputVideoPath,
          finalVideoPath,
          voiceoverPath,
          musicPath,
          duration,
          options.musicVolume || 0.3
        );

        fs.renameSync(finalVideoPath, outputVideoPath);
      }

      // 7. Verificar arquivo final
      if (!fs.existsSync(outputVideoPath)) {
        throw new Error('V√≠deo n√£o foi gerado pelo FFmpeg');
      }

      const videoStats = fs.statSync(outputVideoPath);
      console.log(`\nüì¶ Tamanho do v√≠deo: ${(videoStats.size / 1024 / 1024).toFixed(2)} MB`);

      console.log('\n‚úÖ ========== V√çDEO ENHANCED COMPLETO ==========');
      console.log(`üìπ V√≠deo: ${outputVideoPath}`);
      console.log(`‚è±Ô∏è Dura√ß√£o: ${duration}s`);
      console.log(`üñºÔ∏è Slides: ${imageUrls.length}`);
      console.log(`üí∞ Custo: $${totalCost.toFixed(3)}`);

      return {
        video_url: outputVideoPath,
        duration_seconds: duration,
        total_slides: imageUrls.length,
        content_id: contentId,
        cost_usd: totalCost,
        voiceover_url: voiceoverPath,
        music_used: !!musicPath,
        transitions_used: options.useFadeTransitions !== false
      };

    } catch (error: any) {
      console.error('‚ùå Erro ao gerar v√≠deo enhanced:', error.message);
      throw error;
    }
  }

  /**
   * Gera √°udios de locu√ß√£o sincronizados por slide com suporte a m√∫ltiplas vozes
   */
  private async generateSyncedVoiceovers(
    scriptsPerSlide: string[],
    tempDir: string,
    voicesPerSlide?: ('bruno' | 'carla')[]
  ): Promise<{ audioPaths: string[], durations: number[], totalDuration: number }> {
    console.log('\nüéôÔ∏è Gerando locu√ß√µes sincronizadas por slide...');

    const audioPaths: string[] = [];
    const durations: number[] = [];
    let totalDuration = 0;

    for (let i = 0; i < scriptsPerSlide.length; i++) {
      const script = scriptsPerSlide[i];
      if (!script) continue;

      // Determina qual voz usar para este slide
      const voiceType = voicesPerSlide?.[i] || 'bruno';
      const voiceId = voiceType === 'carla' ? this.ELEVENLABS_VOICE_ID_CARLA : this.ELEVENLABS_VOICE_ID_BRUNO;
      const voiceEmoji = voiceType === 'carla' ? 'üë© Carla' : 'üßî Bruno';

      const audioPath = path.join(tempDir, `voiceover-slide-${i + 1}.mp3`);

      console.log(`   üé§ Slide ${i + 1} (${voiceEmoji}): "${script.substring(0, 50)}..."`);

      // Gerar √°udio
      const response = await axios.post(
        `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`,
        {
          text: script,
          model_id: 'eleven_multilingual_v2',
          voice_settings: {
            stability: 0.35,
            similarity_boost: 0.75,
            style: 0.3,
            use_speaker_boost: true
          }
        },
        {
          headers: {
            'xi-api-key': this.ELEVENLABS_API_KEY,
            'Content-Type': 'application/json'
          },
          responseType: 'arraybuffer'
        }
      );

      fs.writeFileSync(audioPath, response.data);
      audioPaths.push(audioPath);

      // Detectar dura√ß√£o do √°udio
      const durationOutput = await execAsync(
        `ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "${audioPath}"`
      );
      const duration = parseFloat(durationOutput.stdout.trim());
      durations.push(duration);
      totalDuration += duration;

      console.log(`   ‚úÖ Slide ${i + 1}: ${duration.toFixed(2)}s de √°udio gerado`);
    }

    console.log(`\nüìä Dura√ß√£o total da narra√ß√£o: ${totalDuration.toFixed(2)}s`);

    return { audioPaths, durations, totalDuration };
  }

  /**
   * Gera √°udio de locu√ß√£o via ElevenLabs
   */
  private async generateVoiceover(script: string, tempDir: string): Promise<string> {
    const voiceoverPath = path.join(tempDir, 'voiceover.mp3');

    const response = await axios.post(
      `https://api.elevenlabs.io/v1/text-to-speech/${this.ELEVENLABS_VOICE_ID_BRUNO}`,
      {
        text: script,
        model_id: 'eleven_multilingual_v2',
        voice_settings: {
          stability: 0.35,        // Reduzido de 0.5 para fala mais lenta e expressiva
          similarity_boost: 0.75,
          style: 0.3,             // Adiciona mais varia√ß√£o tonal
          use_speaker_boost: true // Melhora clareza da voz
        }
      },
      {
        headers: {
          'xi-api-key': this.ELEVENLABS_API_KEY,
          'Content-Type': 'application/json'
        },
        responseType: 'arraybuffer'
      }
    );

    fs.writeFileSync(voiceoverPath, response.data);
    return voiceoverPath;
  }

  /**
   * Gera v√≠deo COM transi√ß√µes fade E √°udios sincronizados por slide (NOVO)
   */
  private async generateVideoWithFadeTransitionsSynced(
    imagePaths: string[],
    outputPath: string,
    durationsPerSlide: number[],
    transitionDuration: number,
    voiceoverPaths: string[]
  ): Promise<void> {
    console.log('\\nüé¨ Gerando v√≠deo com transi√ß√µes fade e sincroniza√ß√£o...');
    console.log(`   ‚ú® Dura√ß√£o da transi√ß√£o: ${transitionDuration}s`);

    // Criar segmentos de v√≠deo individuais SEM √°udio primeiro
    const videoSegments: string[] = [];

    for (let i = 0; i < imagePaths.length; i++) {
      const imagePath = imagePaths[i];
      if (!imagePath) continue;

      const duration = durationsPerSlide[i] || 10;
      const segmentPath = path.join(path.dirname(outputPath), `segment-${i.toString().padStart(2, '0')}.mp4`);

      console.log(`   üéûÔ∏è Criando segmento ${i + 1}/${imagePaths.length} (${duration.toFixed(2)}s)...`);

      // Criar v√≠deo SEM √°udio (√°udio ser√° adicionado depois)
      const segmentCommand = `ffmpeg -loop 1 -i "${imagePath}" \
        -vf "scale=1080:1080:force_original_aspect_ratio=increase,crop=1080:1080,fps=30,format=yuv420p" \
        -c:v libx264 -preset medium -crf 23 -t ${duration} -y "${segmentPath}"`;

      await execAsync(segmentCommand);
      videoSegments.push(segmentPath);
    }

    console.log(`   ‚ú® Aplicando ${videoSegments.length - 1} transi√ß√µes fade...`);

    // Aplicar xfade recursivamente APENAS no v√≠deo (sem √°udio)
    let currentVideo: string = videoSegments[0]!;
    let currentDuration = durationsPerSlide[0] || 10;

    for (let i = 1; i < videoSegments.length; i++) {
      const tempOutput = path.join(path.dirname(outputPath), `merged-${i}.mp4`);
      const nextVideo = videoSegments[i]!;
      const offset = currentDuration - transitionDuration;

      console.log(`   üîó Mesclando slide ${i + 1} (current: ${currentDuration.toFixed(2)}s, offset: ${offset.toFixed(2)}s)...`);

      // Xfade APENAS para v√≠deo (sem √°udio)
      const xfadeCommand = `ffmpeg -i "${currentVideo}" -i "${nextVideo}" \
        -filter_complex "[0:v][1:v]xfade=transition=fade:duration=${transitionDuration}:offset=${offset.toFixed(2)}[vout]" \
        -map "[vout]" \
        -c:v libx264 -preset medium -crf 23 \
        -y "${tempOutput}"`;

      await execAsync(xfadeCommand);

      currentDuration = currentDuration + (durationsPerSlide[i] || 10) - transitionDuration;
      currentVideo = tempOutput;
    }

    // Agora adicionar √°udio sincronizado ao v√≠deo com transi√ß√µes
    const videoWithTransitions = currentVideo;
    const finalVideoWithAudio = path.join(path.dirname(outputPath), 'final-with-audio.mp4');

    console.log('   üé§ Adicionando √°udios sincronizados ao v√≠deo...');

    // Criar arquivo de concat para os √°udios
    const audioListPath = path.join(path.dirname(outputPath), 'audio-list.txt');
    let audioListContent = '';
    for (const audioPath of voiceoverPaths) {
      if (audioPath) {
        audioListContent += `file '${audioPath}'\n`;
      }
    }
    fs.writeFileSync(audioListPath, audioListContent);

    // Concatenar todos os √°udios e adicionar ao v√≠deo
    const addAudioCommand = `ffmpeg -i "${videoWithTransitions}" -f concat -safe 0 -i "${audioListPath}" \
      -c:v copy -c:a aac -b:a 192k -shortest \
      -y "${finalVideoWithAudio}"`;

    await execAsync(addAudioCommand);
    fs.renameSync(finalVideoWithAudio, outputPath);

    console.log('   ‚úÖ Transi√ß√µes e sincroniza√ß√£o aplicadas com sucesso');
  }

  /**
   * Gera v√≠deo SEM transi√ß√µes MAS com √°udios sincronizados (NOVO)
   */
  private async generateVideoSimpleSynced(
    imagePaths: string[],
    outputPath: string,
    durationsPerSlide: number[],
    voiceoverPaths: string[]
  ): Promise<void> {
    console.log('\\nüé¨ Gerando v√≠deo sincronizado sem transi√ß√µes...');

    const videoSegments: string[] = [];

    for (let i = 0; i < imagePaths.length; i++) {
      const imagePath = imagePaths[i];
      if (!imagePath) continue;

      const duration = durationsPerSlide[i] || 10;
      const segmentPath = path.join(path.dirname(outputPath), `segment-${i.toString().padStart(2, '0')}.mp4`);

      console.log(`   üéûÔ∏è Criando segmento ${i + 1}/${imagePaths.length} (${duration.toFixed(2)}s)...`);

      let segmentCommand = `ffmpeg -loop 1 -i "${imagePath}"`;

      if (voiceoverPaths[i]) {
        segmentCommand += ` -i "${voiceoverPaths[i]}"`;
      }

      segmentCommand += ` -vf "scale=1080:1080:force_original_aspect_ratio=increase,crop=1080:1080,fps=30,format=yuv420p" \
        -c:v libx264 -preset medium -crf 23`;

      if (voiceoverPaths[i]) {
        segmentCommand += ` -c:a aac -b:a 192k -shortest`;
      }

      segmentCommand += ` -t ${duration} -y "${segmentPath}"`;

      await execAsync(segmentCommand);
      videoSegments.push(segmentPath);
    }

    // Concatenar
    const listFilePath = path.join(path.dirname(outputPath), 'segments.txt');
    let listContent = '';
    for (const segment of videoSegments) {
      listContent += `file '${segment}'\n`;
    }
    fs.writeFileSync(listFilePath, listContent);

    const concatCommand = `ffmpeg -f concat -safe 0 -i "${listFilePath}" \
      -c copy -movflags +faststart \
      -y "${outputPath}"`;

    await execAsync(concatCommand);
    console.log('   ‚úÖ V√≠deo sincronizado concatenado');
  }

  /**
   * Gera v√≠deo COM transi√ß√µes fade usando xfade filter do FFmpeg
   * ABORDAGEM RECURSIVA: Aplica xfade um por vez para evitar problemas de offset
   */
  private async generateVideoWithFadeTransitions(
    imagePaths: string[],
    outputPath: string,
    durationPerSlide: number,
    transitionDuration: number
  ): Promise<void> {
    console.log('\nüé¨ Gerando v√≠deo com transi√ß√µes fade...');
    console.log(`   ‚ú® Dura√ß√£o da transi√ß√£o: ${transitionDuration}s`);

    // Criar segmentos de v√≠deo individuais
    const videoSegments: string[] = [];

    for (let i = 0; i < imagePaths.length; i++) {
      const imagePath = imagePaths[i];
      if (!imagePath) continue;

      const segmentPath = path.join(path.dirname(outputPath), `segment-${i.toString().padStart(2, '0')}.mp4`);

      console.log(`   üéûÔ∏è Criando segmento ${i + 1}/${imagePaths.length}...`);

      const segmentCommand = `ffmpeg -loop 1 -i "${imagePath}" \
        -vf "scale=1080:1080:force_original_aspect_ratio=increase,crop=1080:1080,fps=30,format=yuv420p" \
        -c:v libx264 -preset medium -crf 23 \
        -t ${durationPerSlide} \
        -y "${segmentPath}"`;

      await execAsync(segmentCommand);
      videoSegments.push(segmentPath);
    }

    console.log(`   ‚ú® Aplicando ${videoSegments.length - 1} transi√ß√µes fade...`);

    // Aplicar xfade recursivamente (um por vez)
    let currentVideo: string = videoSegments[0]!;
    let currentDuration = durationPerSlide; // Dura√ß√£o real do v√≠deo atual

    for (let i = 1; i < videoSegments.length; i++) {
      const tempOutput = path.join(path.dirname(outputPath), `merged-${i}.mp4`);
      const nextVideo = videoSegments[i]!;

      // Offset CORRETO: dura√ß√£o do v√≠deo atual menos a dura√ß√£o da transi√ß√£o
      const offset = currentDuration - transitionDuration;

      console.log(`   üîó Mesclando slide ${i + 1} (current: ${currentDuration.toFixed(2)}s, offset: ${offset.toFixed(2)}s)...`);

      const xfadeCommand = `ffmpeg -i "${currentVideo}" -i "${nextVideo}" \
        -filter_complex "[0:v][1:v]xfade=transition=fade:duration=${transitionDuration}:offset=${offset.toFixed(2)}[v]" \
        -map "[v]" \
        -c:v libx264 -preset medium -crf 23 \
        -y "${tempOutput}"`;

      await execAsync(xfadeCommand);

      // Atualizar dura√ß√£o: v√≠deo atual + novo slide - overlap da transi√ß√£o
      currentDuration = currentDuration + durationPerSlide - transitionDuration;

      // Usar o merged como current para pr√≥xima itera√ß√£o
      currentVideo = tempOutput;
    }

    // Mover v√≠deo final para output path
    fs.renameSync(currentVideo, outputPath);
    console.log('   ‚úÖ Transi√ß√µes aplicadas com sucesso');
  }

  /**
   * Gera v√≠deo SEM transi√ß√µes (concatena√ß√£o simples)
   */
  private async generateVideoSimple(
    imagePaths: string[],
    outputPath: string,
    durationPerSlide: number
  ): Promise<void> {
    console.log('\nüé¨ Gerando v√≠deo sem transi√ß√µes...');

    const videoSegments: string[] = [];

    for (let i = 0; i < imagePaths.length; i++) {
      const imagePath = imagePaths[i];
      if (!imagePath) continue;

      const segmentPath = path.join(path.dirname(outputPath), `segment-${i.toString().padStart(2, '0')}.mp4`);

      console.log(`   üéûÔ∏è Criando segmento ${i + 1}/${imagePaths.length}...`);

      const segmentCommand = `ffmpeg -loop 1 -i "${imagePath}" \
        -vf "scale=1080:1080:force_original_aspect_ratio=increase,crop=1080:1080,fps=30,format=yuv420p" \
        -c:v libx264 -preset medium -crf 23 \
        -t ${durationPerSlide} \
        -y "${segmentPath}"`;

      await execAsync(segmentCommand);
      videoSegments.push(segmentPath);
    }

    // Concatenar
    const listFilePath = path.join(path.dirname(outputPath), 'segments.txt');
    let listContent = '';
    for (const segment of videoSegments) {
      listContent += `file '${segment}'\n`;
    }
    fs.writeFileSync(listFilePath, listContent);

    const concatCommand = `ffmpeg -f concat -safe 0 -i "${listFilePath}" \
      -c copy \
      -movflags +faststart \
      -y "${outputPath}"`;

    await execAsync(concatCommand);
    console.log('   ‚úÖ V√≠deo concatenado');
  }

  /**
   * Adiciona locu√ß√£o e m√∫sica ao v√≠deo
   */
  private async addAudioToVideo(
    videoPath: string,
    outputPath: string,
    voiceoverPath: string | undefined,
    musicPath: string | undefined,
    duration: number,
    musicVolume: number
  ): Promise<void> {
    let audioFilterComplex = '';
    let inputs = `-i "${videoPath}"`;
    let mapAudio = '';

    if (voiceoverPath && musicPath) {
      // Locu√ß√£o + M√∫sica
      inputs += ` -i "${voiceoverPath}" -i "${musicPath}"`;

      // Aplicar fade in/out na m√∫sica, ajustar volume, e mixar com locu√ß√£o
      audioFilterComplex = `-filter_complex "\
[2:a]volume=${musicVolume},afade=t=in:st=0:d=2,afade=t=out:st=${duration - 2}:d=2[music];\
[1:a][music]amix=inputs=2:duration=longest:weights=1 ${musicVolume}[audio]" \
-map 0:v -map "[audio]"`;

    } else if (voiceoverPath) {
      // Apenas locu√ß√£o
      inputs += ` -i "${voiceoverPath}"`;
      mapAudio = '-map 0:v -map 1:a';

    } else if (musicPath) {
      // Apenas m√∫sica
      inputs += ` -i "${musicPath}"`;
      audioFilterComplex = `-filter_complex "\
[1:a]volume=${musicVolume},afade=t=in:st=0:d=2,afade=t=out:st=${duration - 2}:d=2[audio]" \
-map 0:v -map "[audio]"`;
    }

    const command = `ffmpeg ${inputs} ${audioFilterComplex || mapAudio} \
      -c:v copy -c:a aac -b:a 192k \
      -shortest \
      -y "${outputPath}"`;

    await execAsync(command);
    console.log('   ‚úÖ √Åudio adicionado ao v√≠deo');
  }
}
