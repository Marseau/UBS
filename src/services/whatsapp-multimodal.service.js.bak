"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.WhatsAppMultiModalService = void 0;
const multimodal_helpers_service_1 = require("./multimodal-helpers.service");
const advanced_intent_recognition_service_1 = require("./advanced-intent-recognition.service");
class WhatsAppMultiModalService {
    constructor() {
        this.helpers = new multimodal_helpers_service_1.MultiModalHelpers();
        this.intentService = new advanced_intent_recognition_service_1.AdvancedIntentRecognitionService();
    }
    async processMultiModalMessage(textMessage, mediaFiles, context) {
        console.log(`üîÑ Processando mensagem multi-modal: texto + ${mediaFiles.length} arquivos`);
        const textIntent = await this.intentService.recognizeIntent(textMessage, context);
        console.log(`üìù Intent do texto: ${textIntent.type} (${(textIntent.confidence * 100).toFixed(1)}%)`);
        const multiModalContent = [];
        for (let i = 0; i < mediaFiles.length; i++) {
            const file = mediaFiles[i];
            const content = {
                id: `media_${Date.now()}_${i}`,
                type: this.determineContentType(file.mimetype),
                content: file.buffer,
                mimeType: file.mimetype,
                filename: file.filename,
                metadata: {
                    size: file.buffer.length
                },
                timestamp: new Date()
            };
            multiModalContent.push(content);
            console.log(`üìé Adicionado: ${content.type} (${this.formatFileSize(content.metadata?.size || 0)})`);
        }
        const analyses = [];
        for (const content of multiModalContent) {
            try {
                let analysis;
                switch (content.type) {
                    case 'audio':
                        analysis = await this.processAudio(content);
                        break;
                    case 'image':
                        analysis = await this.processImage(content);
                        break;
                    case 'document':
                        analysis = await this.processDocument(content);
                        break;
                    case 'video':
                        analysis = await this.processVideo(content);
                        break;
                    default:
                        analysis = await this.processGeneric(content);
                }
                analyses.push(analysis);
                console.log(`‚úÖ ${content.type} processado: confian√ßa ${(analysis.confidence * 100).toFixed(1)}%`);
            }
            catch (error) {
                console.error(`‚ùå Erro processando ${content.type}:`, error);
                const fallbackAnalysis = {
                    contentId: content.id,
                    contentType: content.type,
                    primaryAnalysis: `Erro ao processar ${content.type}: ${error}`,
                    entities: [],
                    confidence: 0.3,
                    processingTime: 0,
                    warnings: [`Falha no processamento: ${error}`]
                };
                analyses.push(fallbackAnalysis);
            }
        }
        const result = await this.combineAnalyses(textIntent, analyses, context);
        console.log(`üéØ Resultado final: ${result.recommendedAction} (confian√ßa: ${(result.confidence * 100).toFixed(1)}%)`);
        console.log(`üë• Requer humano: ${result.requiresHumanReview ? 'Sim' : 'N√£o'}`);
        return result;
    }
    async processTextOnlyMessage(textMessage, context) {
        return await this.intentService.recognizeIntent(textMessage, context);
    }
    validateMediaFile(buffer, mimetype) {
        const capabilities = this.getCapabilities();
        const contentType = this.determineContentType(mimetype);
        const supportedFormats = capabilities.supportedFormats[contentType];
        if (!supportedFormats || !supportedFormats.includes(mimetype)) {
            return {
                isValid: false,
                error: `Tipo de arquivo n√£o suportado: ${mimetype}`
            };
        }
        const maxSize = capabilities.maxFileSize[contentType];
        if (buffer.length > maxSize) {
            return {
                isValid: false,
                error: `Arquivo muito grande: ${this.formatFileSize(buffer.length)} (m√°ximo: ${this.formatFileSize(maxSize)})`
            };
        }
        return { isValid: true };
    }
    getCapabilities() {
        return {
            supportedFormats: {
                audio: ['audio/wav', 'audio/mp3', 'audio/m4a', 'audio/ogg', 'audio/mpeg'],
                image: ['image/jpeg', 'image/png', 'image/gif', 'image/webp', 'image/jpg'],
                video: ['video/mp4', 'video/mov', 'video/avi', 'video/quicktime'],
                document: ['application/pdf', 'text/plain', 'application/msword', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document']
            },
            maxFileSize: {
                audio: 25 * 1024 * 1024,
                image: 20 * 1024 * 1024,
                video: 100 * 1024 * 1024,
                document: 50 * 1024 * 1024
            }
        };
    }
    generateContextualResponse(result) {
        const { originalIntent, multiModalEnhancement, recommendedAction, requiresHumanReview } = result;
        const baseResponses = {
            booking_request: 'Entendi que voc√™ gostaria de agendar um servi√ßo.',
            booking_cancel: 'Vou ajudar voc√™ a cancelar seu agendamento.',
            service_inquiry: 'Vou fornecer informa√ß√µes sobre nossos servi√ßos.',
            emergency: 'Entendo que √© uma situa√ß√£o urgente.',
            greeting: 'Ol√°! Como posso ajudar voc√™ hoje?',
            complaint: 'Lamento pelo inconveniente. Vamos resolver isso.',
            compliment: 'Muito obrigado pelo feedback positivo!',
            price_inquiry: 'Vou informar os pre√ßos dos nossos servi√ßos.',
            availability_check: 'Vou verificar nossa disponibilidade.',
            support_request: 'Estou aqui para ajudar voc√™.',
            goodbye: 'Obrigado pelo contato! At√© logo!',
            unknown: 'Vou analisar sua solicita√ß√£o.'
        };
        let response = baseResponses[originalIntent.type] || baseResponses.unknown;
        if (multiModalEnhancement.contentType !== 'text') {
            const mediaTypes = {
                audio: '√°udio',
                image: 'imagem',
                video: 'v√≠deo',
                document: 'documento'
            };
            const mediaType = mediaTypes[multiModalEnhancement.contentType];
            response += ` Analisei tamb√©m o ${mediaType} que voc√™ enviou.`;
        }
        if (multiModalEnhancement.emotionalAnalysis) {
            const emotion = multiModalEnhancement.emotionalAnalysis;
            if (emotion.tone === 'frustrated' || emotion.tone === 'negative') {
                response += ' Percebo que voc√™ pode estar preocupado, vou dar aten√ß√£o especial ao seu caso.';
            }
            else if (emotion.tone === 'positive' || emotion.tone === 'excited') {
                response += ' Fico feliz em perceber seu entusiasmo!';
            }
        }
        switch (recommendedAction) {
            case 'escalate_to_human':
                response += ' Vou conectar voc√™ com um de nossos especialistas para melhor atendimento.';
                break;
            case 'create_appointment':
                response += ' Vou ajudar voc√™ a agendar um hor√°rio.';
                break;
            case 'emergency_response':
                response += ' Trataremos isso como prioridade m√°xima.';
                break;
            case 'human_review':
                response += ' Nossa equipe revisar√° sua solicita√ß√£o pessoalmente.';
                break;
        }
        return response;
    }
    async processAudio(content) {
        console.log('üéµ Processando √°udio...');
        const transcription = await this.helpers.transcribeAudio(content.content, content.mimeType);
        if (transcription.includes('[√Åudio recebido')) {
            return {
                contentId: content.id,
                contentType: 'audio',
                primaryAnalysis: transcription,
                transcription,
                entities: [],
                confidence: 0.6,
                processingTime: 0,
                businessContext: {
                    relevantServices: [],
                    suggestedActions: ['human_review'],
                    urgencyLevel: 'medium',
                    requiresHumanReview: true,
                    contextualInsights: ['√Åudio requer an√°lise manual']
                }
            };
        }
        const [entities, businessContext, emotionalAnalysis] = await Promise.all([
            this.helpers.extractEntitiesFromText(transcription),
            this.helpers.analyzeTextForBusiness(transcription),
            this.helpers.analyzeTextEmotion(transcription)
        ]);
        return {
            contentId: content.id,
            contentType: 'audio',
            primaryAnalysis: transcription,
            transcription,
            entities,
            businessContext,
            emotionalAnalysis,
            confidence: 0.85,
            processingTime: 0
        };
    }
    async processImage(content) {
        console.log('üñºÔ∏è Processando imagem...');
        const [visualDescription, ocrText] = await Promise.all([
            this.helpers.analyzeImageVisually(content.content, content.mimeType),
            this.helpers.extractTextFromImage(content.content, content.mimeType)
        ]);
        const combinedText = `${visualDescription} ${ocrText}`.trim();
        const [entities, businessContext, emotionalAnalysis] = await Promise.all([
            this.helpers.extractEntitiesFromText(combinedText),
            this.helpers.analyzeTextForBusiness(combinedText),
            this.helpers.analyzeTextEmotion(combinedText)
        ]);
        return {
            contentId: content.id,
            contentType: 'image',
            primaryAnalysis: visualDescription,
            visualDescription,
            ocrText,
            entities,
            businessContext,
            emotionalAnalysis,
            confidence: 0.80,
            processingTime: 0
        };
    }
    async processDocument(content) {
        console.log('üìÑ Processando documento...');
        const extractedText = await this.helpers.extractTextFromDocument(content.content, content.mimeType);
        const [entities, businessContext, emotionalAnalysis] = await Promise.all([
            this.helpers.extractEntitiesFromText(extractedText),
            this.helpers.analyzeDocumentForBusiness(extractedText, content.mimeType),
            this.helpers.analyzeTextEmotion(extractedText)
        ]);
        return {
            contentId: content.id,
            contentType: 'document',
            primaryAnalysis: extractedText,
            ocrText: extractedText,
            entities,
            businessContext,
            emotionalAnalysis,
            confidence: 0.90,
            processingTime: 0
        };
    }
    async processVideo(content) {
        console.log('üé• Processando v√≠deo...');
        const basicAnalysis = `V√≠deo recebido (${content.mimeType}, ${this.formatFileSize(content.metadata.size)})`;
        return {
            contentId: content.id,
            contentType: 'video',
            primaryAnalysis: basicAnalysis,
            entities: [],
            confidence: 0.70,
            processingTime: 0,
            businessContext: {
                relevantServices: [],
                suggestedActions: ['human_review'],
                urgencyLevel: 'medium',
                requiresHumanReview: true,
                contextualInsights: ['V√≠deo requer an√°lise manual']
            }
        };
    }
    async processGeneric(content) {
        console.log('üìé Processando arquivo gen√©rico...');
        return {
            contentId: content.id,
            contentType: content.type,
            primaryAnalysis: `Arquivo ${content.type} recebido`,
            entities: [],
            confidence: 0.50,
            processingTime: 0,
            businessContext: {
                relevantServices: [],
                suggestedActions: ['human_review'],
                urgencyLevel: 'low',
                requiresHumanReview: true,
                contextualInsights: ['Arquivo requer an√°lise manual']
            }
        };
    }
    async combineAnalyses(textIntent, analyses, context) {
        const allEntities = [
            ...textIntent.entities,
            ...analyses.flatMap(a => a.entities)
        ];
        const enhancedEntities = this.helpers.combineEntities(allEntities);
        const businessContexts = analyses
            .map(a => a.businessContext)
            .filter(Boolean);
        const combinedBusinessContext = this.helpers.combineBusinessContext(businessContexts);
        const analysisConfidences = analyses.map(a => a.confidence);
        const avgAnalysisConfidence = analysisConfidences.length > 0 ?
            analysisConfidences.reduce((sum, conf) => sum + conf, 0) / analysisConfidences.length : 0;
        const enhancedConfidence = (textIntent.confidence + avgAnalysisConfidence) / 2;
        const requiresHumanReview = combinedBusinessContext.requiresHumanReview ||
            analyses.some(a => a.confidence < 0.7) ||
            analyses.some(a => a.warnings && a.warnings.length > 0) ||
            enhancedConfidence < 0.7;
        const recommendedAction = this.helpers.determineRecommendedAction(textIntent, combinedBusinessContext, enhancedEntities);
        return {
            originalIntent: textIntent,
            multiModalEnhancement: analyses[0] || {
                contentId: 'combined',
                contentType: 'text',
                primaryAnalysis: 'An√°lise multi-modal combinada',
                entities: enhancedEntities,
                confidence: avgAnalysisConfidence,
                processingTime: 0
            },
            enhancedEntities,
            confidence: enhancedConfidence,
            recommendedAction,
            requiresHumanReview
        };
    }
    determineContentType(mimetype) {
        if (mimetype.startsWith('audio/'))
            return 'audio';
        if (mimetype.startsWith('image/'))
            return 'image';
        if (mimetype.startsWith('video/'))
            return 'video';
        if (mimetype.startsWith('text/') ||
            mimetype.includes('pdf') ||
            mimetype.includes('document') ||
            mimetype.includes('word'))
            return 'document';
        return 'document';
    }
    formatFileSize(bytes) {
        if (bytes === 0)
            return '0 Bytes';
        const k = 1024;
        const sizes = ['Bytes', 'KB', 'MB', 'GB'];
        const i = Math.floor(Math.log(bytes) / Math.log(k));
        return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
    }
}
exports.WhatsAppMultiModalService = WhatsAppMultiModalService;
exports.default = WhatsAppMultiModalService;
//# sourceMappingURL=whatsapp-multimodal.service.js.map