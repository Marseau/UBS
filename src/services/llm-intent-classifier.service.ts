/**
 * LLM Intent Classifier Service - Camada 2
 * Classificador LLM fechado com temperature=0 e valida√ß√£o rigorosa contra allowlist
 * S√≥ √© chamada quando detector determin√≠stico retorna null
 */

import OpenAI from 'openai';
import { INTENT_KEYS, IntentKey } from './deterministic-intent-detector.service';

export interface LLMClassificationResult {
  intent: string | null;
  decision_method: 'llm_classification';
  confidence: number;
  processing_time_ms: number;
  model_used?: string;
  // ‚úÖ ADICIONAR M√âTRICAS OPENAI COMPLETAS
  usage?: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
  api_cost_usd?: number;
  raw_response?: any;
}

export class LLMIntentClassifierService {
  private openai: OpenAI;
  private config: any;
  
  constructor() {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY || ''
    });
    
    // Config para escalonamento de modelos
    this.config = {
      openai: {
        models: ['gpt-4o-mini', 'gpt-3.5-turbo', 'gpt-4'],
        temperature: 0,
        maxTokens: 20
      }
    };
  }

  /**
   * ‚úÖ Escalonamento de modelos: tenta em ordem at√© bater confian√ßa m√≠nima
   */
  private async classifyWithEscalation(
    userText: string,
    systemPrompt: string,
    minConfidence = 0.75
  ): Promise<{ intent: string | null; confidence: number; model_used: string; raw?: any; usage?: any }> {
    const models = (this.config?.openai?.models && this.config.openai.models.length > 0)
      ? this.config.openai.models
      : ['gpt-4o-mini', 'gpt-3.5-turbo', 'gpt-4'];

    let lastError: any;
    for (const model of models) {
      try {
        const supportsJsonMode = model.includes('gpt-4o') || model.includes('gpt-3.5-turbo') || model === 'gpt-4o-mini';
        
        const resp = await this.openai.chat.completions.create({
          model,
          temperature: this.config?.openai?.temperature ?? 0,
          top_p: 0,
          max_tokens: this.config?.openai?.maxTokens ?? 20,
          ...(supportsJsonMode && { response_format: { type: 'json_object' } }),
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userText }
          ]
        });

        const rawResponse = resp.choices?.[0]?.message?.content?.trim() || '';
        
        // Parse e valida√ß√£o rigorosa usando m√©todo existente
        const classifiedIntent = this.parseAndValidateResponse(rawResponse);
        const confidence = classifiedIntent ? 0.8 : 0.0; // 80% para LLM v√°lida, 0% para null

        if (classifiedIntent && confidence >= minConfidence) {
          return { 
            intent: classifiedIntent, 
            confidence, 
            model_used: model, 
            raw: resp,
            usage: resp.usage
          };
        }
        // baixa confian√ßa ‚Üí tenta pr√≥ximo modelo
      } catch (err) {
        lastError = err;
        // falha do modelo ‚Üí tenta pr√≥ximo
      }
    }

    // Se todos falharam/baixa confian√ßa ‚Üí retorna nulo com √∫ltimo modelo
    return { 
      intent: null, 
      confidence: 0, 
      model_used: models[models.length - 1], 
      raw: lastError,
      usage: undefined 
    };
  }

  /**
   * Classifica intent usando LLM com temperatura 0 e valida√ß√£o rigorosa
   */
  async classifyIntent(text: string): Promise<LLMClassificationResult> {
    const startTime = Date.now();
    
    try {
      const systemPrompt = this.buildSystemPrompt();
      const userPrompt = this.buildUserPrompt(text);

      console.log('ü§ñ [LLM-CLASSIFIER] Chamando OpenAI para classifica√ß√£o fechada com escalonamento');

      // Usar escalonamento de modelos
      const { intent, confidence, model_used, usage, raw } = 
        await this.classifyWithEscalation(userPrompt, systemPrompt, 0.75);

      const processingTime = Date.now() - startTime;
      
      // ‚úÖ CALCULAR CUSTO DA API
      const apiCost = this.calculateOpenAICost(usage, model_used);
      
      console.log(`ü§ñ [LLM-CLASSIFIER] Intent classificada: ${intent} (${processingTime}ms) [${model_used}] - R$ ${(apiCost || 0).toFixed(6)}`);

      return {
        intent,
        decision_method: 'llm_classification',
        confidence,
        processing_time_ms: processingTime,
        model_used,
        usage,
        api_cost_usd: apiCost || undefined,
        raw_response: raw
      };

    } catch (error) {
      console.error('üö® [LLM-CLASSIFIER] Erro na classifica√ß√£o:', error);
      return {
        intent: null,
        decision_method: 'llm_classification',
        confidence: 0.0,
        processing_time_ms: Date.now() - startTime,
        model_used: 'error'
      };
    }
  }

  /**
   * Constr√≥i prompt system para classifica√ß√£o fechada
   */
  private buildSystemPrompt(): string {
    const allowedIntents = INTENT_KEYS.join('\n- ');
    
    return `Voc√™ √© um classificador de inten√ß√£o. Classifique a mensagem do usu√°rio em EXATAMENTE UMA das chaves abaixo e nada al√©m disso.

INTENTS PERMITIDAS:
- ${allowedIntents}

Regras:
1) Responda SOMENTE com JSON no formato: {"intent":"<uma-das-chaves>"}.
2) Se N√ÉO for poss√≠vel classificar com seguran√ßa, responda exatamente: {"intent":null}.
3) N√£o explique. N√£o inclua texto extra. Sem sin√¥nimos fora da lista.
4) Use APENAS as chaves exatas da lista acima.
5) Se houver m√∫ltiplas possibilidades, escolha a mais prov√°vel.`;
  }

  /**
   * Constr√≥i prompt user com a mensagem
   */
  private buildUserPrompt(text: string): string {
    return `Mensagem do usu√°rio (pt-BR):
---
${text}
---
Classifique.`;
  }

  /**
   * Parse e valida√ß√£o com rigor m√°ximo contra allowlist
   */
  private parseAndValidateResponse(rawResponse: string): string | null {
    try {
      // Parse JSON
      const parsed = JSON.parse(rawResponse);
      
      // Verificar estrutura b√°sica
      if (!parsed || typeof parsed.intent === 'undefined') {
        console.warn('üö® [LLM-CLASSIFIER] Resposta sem campo intent:', rawResponse);
        return null;
      }

      // Se intent √© explicitamente null
      if (parsed.intent === null) {
        console.log('ü§ñ [LLM-CLASSIFIER] LLM retornou null (n√£o conseguiu classificar)');
        return null;
      }

      // Valida√ß√£o rigorosa contra allowlist
      const intentCandidate = parsed.intent as string;
      const isValid = (INTENT_KEYS as readonly string[]).includes(intentCandidate);

      if (!isValid) {
        console.warn(`üö® [LLM-CLASSIFIER] Intent "${intentCandidate}" N√ÉO est√° na allowlist. Rejeitando.`);
        return null;
      }

      // Valida√ß√£o passou - intent aprovada
      console.log(`‚úÖ [LLM-CLASSIFIER] Intent "${intentCandidate}" validada contra allowlist`);
      return intentCandidate;

    } catch (error) {
      console.error('üö® [LLM-CLASSIFIER] Erro no parse JSON:', error, 'Raw:', rawResponse);
      return null;
    }
  }

  /**
   * ‚úÖ Calcula custo estimado da chamada OpenAI
   */
  private calculateOpenAICost(usage: any, model?: string): number | null {
    if (!usage || !usage.prompt_tokens || !usage.completion_tokens) {
      return null;
    }

    // üí∞ CUSTOS CORRETOS POR MODELO (por 1K tokens)
    const modelCosts: Record<string, { prompt: number; completion: number }> = {
      'gpt-4o-mini': { prompt: 0.00015, completion: 0.0006 },
      'gpt-3.5-turbo': { prompt: 0.0015, completion: 0.002 },
      'gpt-4': { prompt: 0.03, completion: 0.06 },
      'gpt-4o': { prompt: 0.005, completion: 0.015 }
    };

    // Detectar modelo atual ou usar fallback gen√©rico
    const costs = modelCosts[model || 'gpt-4o-mini'] || modelCosts['gpt-4o-mini'];
    
    const promptCost = (usage.prompt_tokens / 1000) * costs!.prompt;
    const completionCost = (usage.completion_tokens / 1000) * costs!.completion;
    
    return Math.round((promptCost + completionCost) * 1000000) / 1000000; // 6 casas decimais para precis√£o
  }

  /**
   * M√©todo utilit√°rio para testar a classifica√ß√£o
   */
  async testClassification(testMessages: string[]): Promise<void> {
    console.log('üß™ [LLM-CLASSIFIER] Iniciando testes de classifica√ß√£o...');
    
    for (const message of testMessages) {
      const result = await this.classifyIntent(message);
      console.log(`üìù "${message}" ‚Üí ${result.intent || 'null'} (${result.processing_time_ms}ms) - R$ ${(result.api_cost_usd || 0).toFixed(6)}`);
    }
  }
}