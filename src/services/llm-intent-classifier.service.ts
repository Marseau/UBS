/**
 * LLM Intent Classifier Service - Camada 2
 * Classificador LLM fechado com temperature=0 e valida√ß√£o rigorosa contra allowlist
 * S√≥ √© chamada quando detector determin√≠stico retorna null
 */

import OpenAI from 'openai';
import { INTENT_KEYS, IntentKey } from './deterministic-intent-detector.service';

export interface LLMClassificationResult {
  intent: string | null;
  decision_method: 'llm_classification';
  confidence_score: number;
  processing_time_ms: number;
  model_used?: string;
  // ‚úÖ ADICIONAR M√âTRICAS OPENAI COMPLETAS
  usage?: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
  api_cost_usd?: number;
  processing_cost_usd?: number; // ADICIONADO: Custo de processamento
  raw_response?: any;
}

export class LLMIntentClassifierService {
  private openai: OpenAI;
  private config: any;
  
  constructor() {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY || ''
    });
    
    // Config para escalonamento de modelos
    this.config = {
      openai: {
        models: ['gpt-4o-mini', 'gpt-3.5-turbo', 'gpt-4'],
        temperature: 0,
        maxTokens: 20
      }
    };
  }

  /**
   * ‚úÖ Escalonamento de modelos: tenta em ordem at√© bater confian√ßa m√≠nima
   */
  private async classifyWithEscalation(
    userText: string,
    systemPrompt: string,
    minConfidence = 0.75
  ): Promise<{ intent: string | null; confidence_score: number; model_used: string; raw?: any; usage?: any }> {
    const models = (this.config?.openai?.models && this.config.openai.models.length > 0)
      ? this.config.openai.models
      : ['gpt-4o-mini', 'gpt-3.5-turbo', 'gpt-4'];

    let lastError: any;
    for (const model of models) {
      try {
        const supportsJsonMode = model.includes('gpt-4o') || model.includes('gpt-3.5-turbo') || model === 'gpt-4o-mini';
        
        const resp = await this.openai.chat.completions.create({
          model,
          temperature: this.config?.openai?.temperature ?? 0,
          top_p: 0,
          max_tokens: this.config?.openai?.maxTokens ?? 20,
          ...(supportsJsonMode && { response_format: { type: 'json_object' } }),
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userText }
          ]
        });

        const rawResponse = resp.choices?.[0]?.message?.content?.trim() || '';
        
        // Parse e valida√ß√£o rigorosa usando m√©todo existente
        const classifiedIntent = this.parseAndValidateResponse(rawResponse);
        const confidence = classifiedIntent ? 0.8 : 0.0; // 80% para LLM v√°lida, 0% para null

        if (classifiedIntent && confidence >= minConfidence) {
          return { 
            intent: classifiedIntent, 
            confidence_score: confidence, 
            model_used: model, 
            raw: resp,
            usage: resp.usage
          };
        }
        // baixa confian√ßa ‚Üí tenta pr√≥ximo modelo
      } catch (err) {
        lastError = err;
        // falha do modelo ‚Üí tenta pr√≥ximo
      }
    }

    // Se todos falharam/baixa confian√ßa ‚Üí retorna nulo com √∫ltimo modelo
    return { 
      intent: null, 
      confidence_score: 0, 
      model_used: models[models.length - 1], 
      raw: lastError,
      usage: undefined 
    };
  }

  /**
   * Classifica intent usando LLM com temperatura 0 e valida√ß√£o rigorosa
   */
  async classifyIntent(text: string): Promise<LLMClassificationResult> {
    const startTime = Date.now();
    
    try {
      const systemPrompt = this.buildSystemPrompt();
      const userPrompt = this.buildUserPrompt(text);

      console.log('ü§ñ [LLM-CLASSIFIER] Chamando OpenAI para classifica√ß√£o fechada com escalonamento');

      // Usar escalonamento de modelos
      const { intent, confidence_score, model_used, usage, raw } = 
        await this.classifyWithEscalation(userPrompt, systemPrompt, 0.75);

      const processingTime = Date.now() - startTime;
      
      // ‚úÖ CALCULAR CUSTO DA API
      const apiCost = this.calculateOpenAICost(usage, model_used);
      
      // ‚úÖ CALCULAR CUSTO DE PROCESSAMENTO (f√≥rmula oficial)
      const processingCost = (() => {
        if (!apiCost) return 0.00001;
        const pct = apiCost * 0.10;      // 10% overhead
        const infra = 0.00002;           // Infraestrutura
        const db = 0.00001;              // Database
        return Math.round((apiCost + pct + infra + db) * 1000000) / 1000000;
      })();
      
      console.log(`ü§ñ [LLM-CLASSIFIER] Intent classificada: ${intent} (${processingTime}ms) [${model_used}] - API: R$ ${(apiCost || 0).toFixed(6)} | Processing: R$ ${processingCost.toFixed(6)}`);

      return {
        intent,
        decision_method: 'llm_classification',
        confidence_score: confidence_score,
        processing_time_ms: processingTime,
        model_used,
        usage,
        api_cost_usd: apiCost || undefined,
        processing_cost_usd: processingCost, // ADICIONADO: Custo de processamento
        raw_response: raw
      };

    } catch (error) {
      console.error('üö® [LLM-CLASSIFIER] Erro na classifica√ß√£o:', error);
      return {
        intent: null,
        decision_method: 'llm_classification',
        confidence_score: 0.0,
        processing_time_ms: Date.now() - startTime,
        model_used: 'error'
      };
    }
  }

  /**
   * Constr√≥i prompt system para classifica√ß√£o fechada MULTI-IDIOMA
   */
  private buildSystemPrompt(): string {
    const allowedIntents = INTENT_KEYS.join('\n- ');
    
    return `You are a multilingual intent classifier. Classify the user message into EXACTLY ONE of the keys below and nothing else.
Voc√™ √© um classificador de inten√ß√£o multi-idioma. Classifique a mensagem em EXATAMENTE UMA das chaves abaixo.
Eres un clasificador de intenci√≥n multiidioma. Clasifica el mensaje en EXACTAMENTE UNA de las claves siguientes.
Vous √™tes un classificateur d'intention multilingue. Classifiez le message en EXACTEMENT UNE des cl√©s ci-dessous.

SUPPORTED LANGUAGES / IDIOMAS SUPORTADOS:
üáßüá∑ Portugu√™s | üá∫üá∏ English | üá™üá∏ Espa√±ol | üá´üá∑ Fran√ßais

ALLOWED INTENTS / INTENTS PERMITIDAS:
- ${allowedIntents}

UNIVERSAL RULES / REGRAS UNIVERSAIS:
1) Respond ONLY with JSON: {"intent":"<exact-key>"} | Responda SOMENTE com JSON: {"intent":"<chave-exata>"}
2) If cannot classify safely, respond: {"intent":null} | Se N√ÉO conseguir classificar, responda: {"intent":null}
3) No explanations. No extra text. | Sem explica√ß√µes. Sem texto extra.
4) Use ONLY exact keys from list above. | Use APENAS as chaves exatas da lista acima.
5) If multiple possibilities, choose most likely. | Se m√∫ltiplas possibilidades, escolha a mais prov√°vel.
6) Detect language automatically and classify accordingly. | Detecte o idioma automaticamente e classifique adequadamente.

MULTILINGUAL PATTERNS EXAMPLES / EXEMPLOS MULTI-IDIOMA:
- greeting: "hi", "oi", "hola", "bonjour"
- services: "services", "servi√ßos", "servicios", "services"
- pricing: "price", "pre√ßo", "precio", "prix"
- availability: "availability", "disponibilidade", "disponibilidad", "disponibilit√©"`;
  }

  /**
   * Constr√≥i prompt user com a mensagem MULTI-IDIOMA
   */
  private buildUserPrompt(text: string): string {
    // TODO: Detectar idioma automaticamente usando o sistema determin√≠stico
    // import('./deterministic-intent-detector.service').then(({ detectLanguage }) => {
    //   const langDetection = detectLanguage(text);
    //   console.log(`üåç [LLM-CLASSIFIER] Idioma detectado: ${langDetection.language} (${(langDetection.confidence * 100).toFixed(1)}%)`);
    // }).catch(() => {
    //   // fallback silencioso se n√£o conseguir importar
    // });
    
    return `User message / Mensagem do usu√°rio / Mensaje del usuario / Message de l'utilisateur:
---
${text}
---

Classify this message into one of the allowed intents. Detect the language automatically and classify accordingly.
Classifique esta mensagem em uma das intents permitidas. Detecte o idioma automaticamente.
Clasifica este mensaje en una de las intenciones permitidas. Detecta el idioma autom√°ticamente.
Classifiez ce message dans l'une des intentions autoris√©es. D√©tectez la langue automatiquement.`;
  }

  /**
   * Parse e valida√ß√£o com rigor m√°ximo contra allowlist
   */
  private parseAndValidateResponse(rawResponse: string): string | null {
    try {
      // Parse JSON
      const parsed = JSON.parse(rawResponse);
      
      // Verificar estrutura b√°sica
      if (!parsed || typeof parsed.intent === 'undefined') {
        console.warn('üö® [LLM-CLASSIFIER] Resposta sem campo intent:', rawResponse);
        return null;
      }

      // Se intent √© explicitamente null
      if (parsed.intent === null) {
        console.log('ü§ñ [LLM-CLASSIFIER] LLM retornou null (n√£o conseguiu classificar)');
        return null;
      }

      // Valida√ß√£o rigorosa contra allowlist
      const intentCandidate = parsed.intent as string;
      const isValid = (INTENT_KEYS as readonly string[]).includes(intentCandidate);

      if (!isValid) {
        console.warn(`üö® [LLM-CLASSIFIER] Intent "${intentCandidate}" N√ÉO est√° na allowlist. Rejeitando.`);
        return null;
      }

      // Valida√ß√£o passou - intent aprovada
      console.log(`‚úÖ [LLM-CLASSIFIER] Intent "${intentCandidate}" validada contra allowlist`);
      return intentCandidate;

    } catch (error) {
      console.error('üö® [LLM-CLASSIFIER] Erro no parse JSON:', error, 'Raw:', rawResponse);
      return null;
    }
  }

  /**
   * ‚úÖ Calcula custo estimado da chamada OpenAI
   */
  private calculateOpenAICost(usage: any, model?: string): number | null {
    if (!usage || !usage.prompt_tokens || !usage.completion_tokens) {
      return null;
    }

    // üí∞ CUSTOS CORRETOS POR MODELO (por 1K tokens)
    const modelCosts: Record<string, { prompt: number; completion: number }> = {
      'gpt-4o-mini': { prompt: 0.00015, completion: 0.0006 },
      'gpt-3.5-turbo': { prompt: 0.0015, completion: 0.002 },
      'gpt-4': { prompt: 0.03, completion: 0.06 },
      'gpt-4o': { prompt: 0.005, completion: 0.015 }
    };

    // Detectar modelo atual ou usar fallback gen√©rico
    const costs = modelCosts[model || 'gpt-4o-mini'] || modelCosts['gpt-4o-mini'];
    
    const promptCost = (usage.prompt_tokens / 1000) * costs!.prompt;
    const completionCost = (usage.completion_tokens / 1000) * costs!.completion;
    
    return Math.round((promptCost + completionCost) * 1000000) / 1000000; // 6 casas decimais para precis√£o
  }

  /**
   * M√©todo utilit√°rio para testar a classifica√ß√£o
   */
  async testClassification(testMessages: string[]): Promise<void> {
    console.log('üß™ [LLM-CLASSIFIER] Iniciando testes de classifica√ß√£o...');
    
    for (const message of testMessages) {
      const result = await this.classifyIntent(message);
      console.log(`üìù "${message}" ‚Üí ${result.intent || 'null'} (${result.processing_time_ms}ms) - R$ ${(result.api_cost_usd || 0).toFixed(6)}`);
    }
  }
}