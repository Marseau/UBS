/**
 * AI Configuration Centralizada
 * 
 * Centraliza configuraÃ§Ã£o do modelo OpenAI usado em todo o sistema.
 * Garante consistÃªncia e facilita mudanÃ§as futuras.
 * 
 * @author PRP-OPENAI-MODEL-UNI
 */

/**
 * Retorna o modelo OpenAI configurado via variÃ¡vel de ambiente
 * com fallback seguro para gpt-4
 * 
 * @returns string - Nome do modelo OpenAI (ex: 'gpt-4', 'gpt-4-turbo')
 */
export function getOpenAIModel(): string {
  const model = process.env.OPENAI_MODEL?.trim() || 'gpt-4';
  
  // Log de debug em desenvolvimento
  if (process.env.NODE_ENV === 'development') {
    console.log(`ðŸ¤– AI Model: ${model} (from ${process.env.OPENAI_MODEL ? 'env' : 'default'})`);
  }
  
  return model;
}

/**
 * Valida se o modelo Ã© um GPT-4 (necessÃ¡rio para produÃ§Ã£o)
 * 
 * @returns boolean - true se modelo comeÃ§a com 'gpt-4'
 */
export function isGpt4(): boolean {
  const model = getOpenAIModel();
  return model.toLowerCase().startsWith('gpt-4');
}

/**
 * ValidaÃ§Ã£o de modelo para produÃ§Ã£o
 * Aborta processo se modelo nÃ£o for gpt-4* em produÃ§Ã£o
 */
export function validateProductionModel(): void {
  if (process.env.NODE_ENV === 'production' && !isGpt4()) {
    const currentModel = getOpenAIModel();
    console.error('ðŸš¨ CRITICAL ERROR: OPENAI_MODEL must be gpt-4* in production');
    console.error(`ðŸ“‹ Current model: ${currentModel}`);
    console.error(`ðŸ“‹ NODE_ENV: ${process.env.NODE_ENV}`);
    console.error(`ðŸ“‹ OPENAI_MODEL env: ${process.env.OPENAI_MODEL || 'not set'}`);
    console.error('ðŸ”§ Fix: Set OPENAI_MODEL=gpt-4 or similar gpt-4* variant');
    
    // Abortar processo em produÃ§Ã£o
    process.exit(1);
  }
}

/**
 * ConfiguraÃ§Ã£o padrÃ£o para OpenAI chat.completions
 * Usar em todos os serviÃ§os que fazem chamadas Ã  API
 */
export const defaultOpenAIConfig = {
  model: getOpenAIModel(),
  temperature: 0.7,
  max_tokens: 1000,
  top_p: 1,
  frequency_penalty: 0,
  presence_penalty: 0
} as const;

/**
 * Log estruturado do modelo usado para telemetria
 * Usar ao gravar dados de conversation_history
 */
export function getModelUsedForTelemetry(): string {
  return getOpenAIModel();
}